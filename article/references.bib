@article{bybee_usage_2006,
  title = {From {{Usage}} to {{Grammar}}: {{The Mind}}'s {{Response}} to {{Repetition}}},
  shorttitle = {From {{Usage}} to {{Grammar}}},
  author = {Bybee, Joan},
  year = {2006},
  journal = {Language},
  volume = {82},
  number = {4},
  pages = {711--733},
  issn = {1535-0665},
  doi = {10.1353/lan.2006.0186},
  urldate = {2021-09-28},
  langid = {english},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\322ZE37D\\Bybee - 2006 - From Usage to Grammar The Mind's Response to Repe.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\7CEDD7D3\\Bybee - 2006 - From Usage to Grammar The Mind's Response to Repe_marked.pdf}
}

@book{bybee_phonology_2003,
  title = {Phonology and {{Language Use}}},
  author = {Bybee, Joan},
  year = {2003},
  month = feb,
  publisher = {Cambridge University Press},
  abstract = {A research perspective that takes language use into account opens up new views of old issues and provides an understanding of issues that linguists have rarely addressed. Referencing new developments in cognitive and functional linguistics, phonetics, and connectionist modeling, this book investigates various ways in which a speaker/hearer's experience with language affects the representation of phonology. Rather than assuming phonological representations in terms of phonemes, Joan Bybee adopts an exemplar model, in which specific tokens of use are stored and categorized phonetically with reference to variables in the context. This model allows an account of phonetically gradual sound change which produces lexical variation, and provides an explanatory account of the fact that many reductive sound changes affect high frequency items first. The well-known effects of type and token frequency on morphologically-conditioned phonological alterations are shown also to apply to larger sequences, such as fixed phrases and constructions, solving some of the problems formulated previously as dealing with the phonology-syntax interface.},
  isbn = {978-0-521-53378-2},
  langid = {english},
  keywords = {Language Arts & Disciplines / Linguistics / General,Language Arts & Disciplines / Linguistics / Historical & Comparative,Language Arts & Disciplines / Linguistics / Morphology,Language Arts & Disciplines / Linguistics / Phonetics & Phonology,Language Arts & Disciplines / Linguistics / Psycholinguistics / General,Medical / General},
  file = {C:\Users\u0128513\Zotero\storage\IPGAUVF4\Bybee - 2003 - Phonology and Language Use.pdf}
}

@inproceedings{mowrey_articulatory_1987,
  title = {Articulatory Evolution},
  booktitle = {7th International Conference on Historical Linguistics},
  author = {Mowrey, Richard and Pagliuca, William and Ramat, Anna Giacalone and Carruba, Onofrio and Bernini, Giuliano},
  year = {1987},
  volume = {1},
  pages = {459--472},
  publisher = {John Benjamins},
  address = {Pavia},
  file = {C:\Users\u0128513\Zotero\storage\7JX5Y6G7\Mowrey et al. - 1987 - Articulatory evolution.pdf}
}

@article{browman_articulatory_2009,
  title = {Articulatory {{Phonology}}: {{An Overview}}},
  shorttitle = {Articulatory {{Phonology}}},
  author = {Browman, Catherine P. and Goldstein, Louis},
  year = {2009},
  month = nov,
  journal = {Phonetica},
  volume = {49},
  number = {3-4},
  pages = {155--180},
  issn = {0031-8388},
  doi = {10.1159/000261913},
  urldate = {2025-07-18},
  abstract = {An overview of the basic ideas of articulatory phonology is presented, along with selected examples of phonological patterning for which the approach seems to provide a particularly insightful account. In articulatory phonology, the basic units of phonological contrast are gestures, which are also abstract characterizations of articulatory events, each with an intrinsic time or duration. Utterances are modeled as organized patterns (constellations) of gestures, in which gestural units may overlap in time. The phonological structures defined in this way provide a set of articulatorily based natural classes. Moreover, the patterns of overlapping organization can be used to specify important aspects of the phonological structure of particular languages, and to account, in a coherent and general way, for a variety of different types of phonological variation. Such variation includes allophonic variation and fluent speech alternations, as well as `coarticulation' and speech errors. Finally, it is suggested that the gestural approach clarifies our understanding of phonological development, by positing that prelinguistic units of action are harnessed into (gestural) phonological structures through differentiation and coordination.},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\USY5VPNN\\Browman and Goldstein - 2009 - Articulatory Phonology An Overview.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\K5KNIA4A\\000261913.html}
}

@inproceedings{fidelholtz_word_1975,
  title = {Word Frequency and Vowel Reduction in {{English}}},
  booktitle = {Papers from the {{Eleventh Regional Meeting}} of the {{Chicago Linguistic Society}}},
  author = {Fidelholtz, James L.},
  year = {1975},
  volume = {11--1},
  pages = {200--213},
  address = {Chicago},
  file = {C:\Users\u0128513\Zotero\storage\HUZ7EHQ6\Fidelholtz - 1975 - Word frequency and vowel reduction in English.pdf}
}

@article{pluymaekers_lexical_2005,
  title = {Lexical Frequency and Acoustic Reduction in Spoken {{Dutch}}},
  author = {Pluymaekers, Mark and Ernestus, Mirjam and Baayen, R. Harald},
  year = {2005},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {118},
  number = {4},
  pages = {2561--2569},
  publisher = {Acoustical Society of America},
  issn = {0001-4966},
  doi = {10.1121/1.2011150},
  urldate = {2023-01-09},
  abstract = {This study investigates the effects of lexical frequency on the durational reduction of morphologically complex words in spoken Dutch. The hypothesis that high-frequency words are more reduced than low-frequency words was tested by comparing the durations of affixes occurring in different carrier words. Four Dutch affixes were investigated, each occurring in a large number of words with different frequencies. The materials came from a large database of face-to-face conversations. For each word containing a target affix, one token was randomly selected for acoustic analysis. Measurements were made of the duration of the affix as a whole and the durations of the individual segments in the affix. For three of the four affixes, a higher frequency of the carrier word led to shorter realizations of the affix as a whole, individual segments in the affix, or both. Other relevant factors were the sex and age of the speaker, segmental context, and speech rate. To accommodate for these findings, models of speech production should allow word frequency to affect the acoustic realizations of lower-level units, such as individual speech sounds occurring in affixes.},
  file = {C:\Users\u0128513\Zotero\storage\MNNRTEQ6\Pluymaekers et al. - 2005 - Lexical frequency and acoustic reduction in spoken.pdf}
}

@article{bybee_effect_1999,
  title = {The Effect of Usage on Degrees of Constituency: The Reduction of Don't in {{English}}},
  shorttitle = {The Effect of Usage on Degrees of Constituency},
  author = {Bybee, Joan and Scheibman, Joanne},
  year = {1999},
  month = jan,
  journal = {Linguistics},
  volume = {37},
  number = {4},
  issn = {0024-3949, 1613-396X},
  doi = {10.1515/ling.37.4.575},
  urldate = {2025-02-28},
  abstract = {In this paper we take the position that there are many degrees of constituency and that these derive in a direct manner from the frequency with which elements are used together: elements that are frequently found next to each other show a tighter constituent structure than those that collocate less frequently. We use both phonological and functional evidence from conversation to argue that repetition conditions chunking (Haiman 1994), sometimes overriding the syntactic and semantic logic of the organization of utterances. Our study examines the reduction of don't in American English conversation. We find that don't is reduced the most in the contexts in which it occurs the most, that is, after I and before certain verbs, such as know. While a generalized constituent structure may be an emergent property arising from many analogous utterances, specific combinations that are frequently used may diverge from the general pattern because frequency conditions autonomy in storage and renders internal analysis unnecessary. This phenomenon reveals the essential role of repetition in the creation of constituent structure: while semantic and pragmatic factors determine what occurs together in discourse, the actual repetition of stretches of talk triggers the chunking mechanism that binds them into constituents.},
  langid = {english},
  file = {C:\Users\u0128513\Zotero\storage\L9MFBX86\Bybee and Scheibman - 1999 - The effect of usage on degrees of constituency the reduction of don't in English.pdf}
}

@article{ernestus_acoustic_2014,
  title = {Acoustic Reduction and the Roles of Abstractions and Exemplars in Speech Processing},
  author = {Ernestus, Mirjam},
  year = {2014},
  month = apr,
  journal = {Lingua},
  series = {{{SI}}: {{Usage-Based}} and {{Rule-Based Approaches}} to {{Phonological Variation}}},
  volume = {142},
  pages = {27--41},
  issn = {0024-3841},
  doi = {10.1016/j.lingua.2012.12.006},
  urldate = {2023-01-09},
  abstract = {Acoustic reduction refers to the frequent phenomenon in conversational speech that words are produced with fewer or lenited segments compared to their citation forms. The few published studies on the production and comprehension of acoustic reduction have important implications for the debate on the relevance of abstractions and exemplars in speech processing. This article discusses these implications. It first briefly introduces the key assumptions of simple abstractionist and simple exemplar-based models. It then discusses the literature on acoustic reduction and draws the conclusion that both types of models need to be extended to explain all findings. The ultimate model should allow for the storage of different pronunciation variants, but also reserve an important role for phonetic implementation. Furthermore, the recognition of a highly reduced pronunciation variant requires top down information and leads to activation of the corresponding unreduced variant, the variant that reaches listeners' consciousness. These findings are best accounted for in hybrids models, assuming both abstract representations and exemplars. None of the hybrid models formulated so far can account for all data on reduced speech and we need further research for obtaining detailed insight into how speakers produce and listeners comprehend reduced speech.},
  langid = {english},
  keywords = {Abstractionist models,Acoustic reduction,Exemplar-based models,Speech comprehension,Speech production,to-read},
  file = {C:\Users\u0128513\Zotero\storage\N6JBKUI8\Ernestus - 2014 - Acoustic reduction and the roles of abstractions a.pdf}
}

@incollection{loreto_theoretical_2010,
  title = {Theoretical {{Tools}} in {{Modeling Communication}} and {{Language Dynamics}}},
  booktitle = {Evolution of {{Communication}} and {{Language}} in {{Embodied Agents}}},
  author = {Loreto, Vittorio},
  editor = {Nolfi, Stefano and Mirolli, Marco},
  year = {2010},
  pages = {67--79},
  publisher = {Springer},
  address = {Berlin},
  isbn = {978-3-642-42499-1},
  langid = {english},
  annotation = {OCLC: 902764877}
}

@incollection{ellis_what_2012,
  title = {What Can We Count in Language, and What Counts in Language Acquisition, Cognition, and Use?},
  booktitle = {Frequency {{Effects}} in {{Language Learning}} and {{Processing}}},
  author = {Ellis, Nick C.},
  editor = {Gries, Stefan Th. and Divjak, Dagmar},
  year = {2012},
  month = aug,
  series = {Trends in {{Linguistics}}. {{Studies}} and {{Monographs}}},
  volume = {244},
  pages = {7--34},
  publisher = {De Gruyter Mouton},
  address = {Berlin},
  urldate = {2024-02-05},
  abstract = {The volume contains a collection of studies on how the analysis of corpus and psycholinguistic data reveal how linguistic knowledge is affected by the frequency of linguistic elements/stimuli. The studies explore a wide range of phenomena , from phonological reduction processes and palatalization to morphological productivity, diachronic change, adjective preposition constructions, auxiliary omission, and multi-word units. The languages studied are Spanish and artificial languages, Russian, Dutch, and English. The sister volume focuses on language representation.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  isbn = {978-3-11-027405-9},
  langid = {english},
  keywords = {Cognitive Linguistics,Corpus Linguistics,Frequency,Psycholinguistics}
}

@book{zipf_psycho-biology_1965,
	address = {Cambridge, Massachusetts},
	title = {The {Psycho}-{Biology} of {Language}},
	language = {en},
	publisher = {MIT Press},
	author = {Zipf, George Kingsley},
	year = {1965},
}

@book{kretzschmar_language_2015,
  title = {Language and {{Complex Systems}}},
  author = {Kretzschmar, William A., Jr},
  year = {2015},
  publisher = {Cambridge University Press},
  address = {Cambridge},
  doi = {10.1017/CBO9781316179017},
  urldate = {2024-01-31},
  abstract = {An understanding of language as a complex system helps us to think differently about linguistics, and helps us to address the impact of linguistic interaction. This book demonstrates how the science of complex systems changes every area of linguistics: how to make a grammar, how to think about the history of language, how language works in the brain, and how it works in social settings. Kretzschmar argues that to construct the best grammars of languages it is necessary to understand the complex system of speech. Each chapter makes specific recommendations for how linguists should manage empirical data in order to form better generalizations about a language and its varieties. The book will be welcomed by students and scholars working in linguistics and English language, especially the study of language variation and the historical development of English.},
  isbn = {978-1-107-10045-9},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\WPK4K8WX\\Kretzschmar - 2015 - Language and Complex Systems.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\SUNVB69Q\\E3EF0E20520DDE8F947EB09E47119922.html}
}

@book{labov_principles_1994,
  title = {Principles of {{Linguistic Change}}, {{Internal Factors}}},
  editor = {Labov, William},
  year = {1994},
  month = jul,
  series = {Principles of {{Linguistic Change}}},
  volume = {1},
  publisher = {Wiley},
  address = {Oxford},
  abstract = {This book develops the general principles of linguistic change that form the foundations of historical linguistics, dialectology and sociolinguistics.~Demonstrates the social as well as cognitive relevance of linguistic researchShows that rapid linguistic change is in progress in the cities of America and England so that urban dialects are becoming more and more differentiatedDiscusses factors that govern the internal development of linguistic structures: the mechanisms of change, the constraints on change, and the ways in which change is embedded in the larger linguistic system},
  googlebooks = {HW4Zf0yuYoIC},
  isbn = {978-0-631-17914-6},
  langid = {english},
  keywords = {Language Arts & Disciplines / General,Language Arts & Disciplines / Linguistics / Sociolinguistics},
  file = {C:\Users\u0128513\Zotero\storage\TLAABWTH\Labov - 1994 - Principles of Linguistic Change, Internal Factors.pdf}
}

@book{zipf_human_1949,
  title = {Human Behavior and the Principle of Least Effort},
  author = {Zipf, George Kingsley},
  year = {1949},
  series = {Human Behavior and the Principle of Least Effort},
  pages = {xi, 573},
  publisher = {Addison-Wesley Press},
  address = {Oxford, England},
  abstract = {Subtitled "An introduction to human ecology," this work attempts systematically to treat "least effort" (and its derivatives) as the principle underlying a multiplicity of individual and collective behaviors, variously but regularly distributed. The general orientation is quantitative, and the principle is widely interpreted and applied. After a brief elaboration of principles and a brief summary of pertinent studies (mostly in psychology), Part One (Language and the structure of the personality) develops 8 chapters on its theme, ranging from regularities within language per se to material on individual psychology. Part Two (Human relations: a case of intraspecies balance) contains chapters on "The economy of geography," "Intranational and international cooperation and conflict," "The distribution of economic power and social status," and "Prestige values and cultural vogues"---all developed in terms of the central theme. 20 pages of references with some annotation, keyed to the index. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {C:\Users\u0128513\Zotero\storage\URECBWM3\1950-00412-000.html}
}

@article{mikolov_efficient_2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  journal = {arXiv:1301.3781 [cs]},
  eprint = {1301.3781},
  primaryclass = {cs},
  urldate = {2022-04-28},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\L3WJN7BY\\Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\HEL5ARRQ\\1301.html}
}

@misc{baevski_wav2vec_2020,
  title = {Wav2vec 2.0: {{A Framework}} for {{Self-Supervised Learning}} of {{Speech Representations}}},
  shorttitle = {Wav2vec 2.0},
  author = {Baevski, Alexei and Zhou, Henry and Mohamed, Abdelrahman and Auli, Michael},
  year = {2020},
  month = oct,
  number = {arXiv:2006.11477},
  eprint = {2006.11477},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2006.11477},
  urldate = {2024-12-02},
  abstract = {We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\JKBY66QZ\\Baevski et al. - 2020 - wav2vec 2.0 A Framework for Self-Supervised Learning of Speech Representations.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\K9HLDFVR\\2006.html}
}

@incollection{de_smet_entrenchment_2016,
  title = {Entrenchment {{Effects}} in {{Language Change}}},
  booktitle = {Entrenchment and the {{Psychology}} of {{Language Learning}}},
  author = {De Smet, Hendrik},
  editor = {Schmid, Hans-J{\"o}rg},
  year = {2016},
  month = dec,
  pages = {75--100},
  publisher = {De Gruyter Mouton},
  urldate = {2023-01-10},
  isbn = {978-3-11-034142-3},
  langid = {english},
  file = {C:\Users\u0128513\Zotero\storage\WB93ZZRA\Smet - 2016 - 4. Entrenchment Effects in Language Change.pdf}
}

@book{leclercq_meaning_2025,
  title = {The {{Meaning}} of {{Constructions}}},
  author = {Leclercq, Beno{\^i}t and Morin, Cameron},
  year = {2025},
  month = may,
  series = {Elements in {{Construction Grammar}}},
  publisher = {Cambridge University Press},
  urldate = {2025-07-03},
  abstract = {Cambridge Core - Grammar and Syntax - The Meaning of Constructions},
  langid = {english},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\2MYC4FT5\\Leclercq and Morin - 2025 - The Meaning of Constructions.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\7LGL5XI4\\0E5A42D30A13D09788819B49A832AF9E.html}
}

@article{smith_models_2014,
  title = {Models of Language Evolution and Change},
  author = {Smith, Andrew D. M.},
  year = {2014},
  journal = {WIREs Cognitive Science},
  volume = {5},
  number = {3},
  pages = {281--293},
  issn = {1939-5086},
  doi = {10.1002/wcs.1285},
  urldate = {2020-10-15},
  abstract = {In the absence of direct evidence of the emergence of language, the explicitness of formal models which allow the exploration of interactions between multiple complex adaptive systems has proven to be an important tool. Computational simulations have been at the heart of the field of evolutionary linguistics for the past two decades, particularly through the language game and iterated learning paradigms, but these are now being extended and complemented in a number of directions, through formal mathematical models, language-ready robotic agents, and experimental simulations in the laboratory. This article is categorized under: Linguistics {$>$} Computational Models of Language Linguistics {$>$} Evolution of Language},
  langid = {english},
  keywords = {overview},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\RB7477CN\\Smith - 2014 - Models of language evolution and change.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\UR2QES7D\\Smith - 2014 - Models of language evolution and change.html}
}

@article{blythe_s-curves_2012,
  title = {S-{{Curves}} and the {{Mechanisms}} of {{Propagation}} in {{Language Change}}},
  author = {Blythe, Richard A. and Croft, William},
  year = {2012},
  journal = {Language},
  volume = {88},
  number = {2},
  eprint = {23251832},
  eprinttype = {jstor},
  pages = {269--304},
  publisher = {Linguistic Society of America},
  issn = {0097-8507},
  urldate = {2022-11-28},
  abstract = {A variety of mechanisms have been proposed in sociolinguistics for the propagation of an innovation through the speech community. The complexity of social systems makes it difficult to evaluate the different mechanisms empirically. We use the four-way typology of mechanisms proposed by Baxter and colleagues (2009), and define them mathematically in such a way that the effects of different mechanisms in the trajectory of a change can be modeled. The model suggests that the widely observed empirical pattern of an S-curve temporal trajectory of change can be captured only if the mechanisms for propagation include replicator selection, that is, differential weighting of the competing variants in a change, except under highly specialized circumstances that probably do not hold in speech communities in general.},
  file = {C:\Users\u0128513\Zotero\storage\A6UT6S9I\Blythe and Croft - 2012 - S-Curves and the Mechanisms of Propagation in Lang.pdf}
}

@article{stanford_revisiting_2013,
  title = {Revisiting Transmission and Diffusion: {{An}} Agent-Based Model of Vowel Chain Shifts across Large Communities},
  shorttitle = {Revisiting Transmission and Diffusion},
  author = {Stanford, James N. and Kenny, Laurence A.},
  year = {2013},
  month = jul,
  journal = {Language Variation and Change},
  volume = {25},
  number = {2},
  pages = {119--153},
  publisher = {Cambridge University Press},
  issn = {0954-3945, 1469-8021},
  doi = {10.1017/S0954394513000069},
  urldate = {2020-11-09},
  abstract = {In this study, we present the first agent-based simulation of vowel chain shifts across large communities, providing a parsimonious reinterpretation of Labov's (2007) notions of transmission, diffusion, and incrementation. Labov determined that parent-to-child transmission faithfully reproduces structural patterns such as the Northern Cities Shift (NCS), but adult-to-adult diffusion does not. NCS is transmitted faithfully to new generations of U.S. Inland North children. But St. Louis speakers, depending only on adult-adult contact, only attain an incomplete, unsystematic version. Labov (2007) attributed the difference to children's superior language-learning ability; transmission and diffusion are categorically different processes in that approach. By contrast, our multiagent simulation suggests that such transmission/diffusion effects can be derived by simple density of interactions and simple exemplar learning; we also find that incrementation is a natural outcome of this model. Unlike Labov (2007), this model does not require a dichotomy between transmission and diffusion. While dichotomous assumptions about child versus adult learning may be necessary in other contexts, our results suggest that the NCS effects in Labov (2007) may be explained economically in terms of simple density of interactions between speakers. Our results also provide an agent-based perspective supporting and explicating the notion of speech community.},
  langid = {english},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\QXAXPIPS\\Stanford and Kenny - 2013 - Revisiting transmission and diffusion An agent-ba.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\CGVFZ76Z\\4F504E6441AB67001CE0E1051517644D.html}
}

@article{pijpops_agent-gebaseerde_2015,
  title = {{Agent-gebaseerde modellering in de historische taalkunde. Een model van regularisatiedruk op de Nederlandse werkwoorden}},
  author = {Pijpops, Dirk and Beuls, Katrien},
  year = {2015},
  month = dec,
  journal = {Handelingen van de Koninklijke Zuid-Nederlandse Maatschappij voor Taal- en Letterkunde en Geschiedenis},
  volume = {69},
  pages = {5--23},
  publisher = {Koninklijke Zuid-Nederlandse Maatschappij voor Taal-, Letterkunde en Geschiedenis},
  issn = {0774-3254},
  urldate = {2020-11-03},
  abstract = {This article presents an accessible introduction to agent-based modelling for non-computational linguists, more specifically historical linguists, who may find it to be a useful addition to their methodological toolbox. We will discuss both the possibilities and limitations of this technique and in doing so, attempt to show how computational modelling can be complementary with the empirical methods of historical linguists. Furthermore, this paper presents a walkthrough of the various steps in the design of such a model. To serve as an example, we will present a basic agent-based model of the competition between regular and irregular verb inflection in Dutch.},
  langid = {dutch},
  keywords = {agent-based,Dutch,frequency,irregular verbs,regular verbs},
  file = {C:\Users\u0128513\Zotero\storage\ZU5CZ28N\Pijpops and Beuls - Agent-gebaseerde modellering in de historische taa.pdf}
}

@inproceedings{python-mesa-2020,
  title = {Utilizing Python for Agent-Based Modeling: {{The}} Mesa Framework},
  booktitle = {Social, Cultural, and Behavioral Modeling},
  author = {Kazil, Jackie and Masad, David and Crooks, Andrew},
  editor = {Thomson, Robert and Bisgin, Halil and Dancy, Christopher and Hyder, Ayaz and Hussain, Muhammad},
  year = {2020},
  pages = {308--317},
  publisher = {Springer International Publishing},
  address = {Cham},
  abstract = {Mesa is an agent-based modeling framework written in Python. Originally started in 2013, it was created to be the go-to tool in for researchers wishing to build agent-based models with Python. Within this paper we present Mesa's design goals, along with its underlying architecture. This includes its core components: 1) the model (Model, Agent, Schedule, and Space), 2) analysis (Data Collector and Batch Runner) and the visualization (Visualization Server and Visualization Browser Page). We then discuss how agent-based models can be created in Mesa. This is followed by a discussion of applications and extensions by other researchers to demonstrate how Mesa design is decoupled and extensible and thus creating the opportunity for a larger decentralized ecosystem of packages that people can share and reuse for their own needs. Finally, the paper concludes with a summary and discussion of future development areas for Mesa.},
  isbn = {978-3-030-61255-9}
}

@article{steels_language_2003,
  title = {Language Re-Entrance and the 'Inner Voice'},
  author = {Steels, Luc},
  year = {2003},
  journal = {Journal of Consciousness Studies},
  volume = {10},
  number = {4-5},
  pages = {173--185},
  publisher = {Imprint Academic},
  address = {US},
  issn = {2051-2201},
  abstract = {As soon as we stop talking aloud, we seem to experience a kind of 'inner voice', a steady stream of verbal fragments expressing ongoing thoughts. What kind of information processing structures are required to explain such a phenomenon? Why would an 'inner voice' be useful? How could it have arisen? This paper explores these questions and reports briefly some computational and robotic experiments to help elucidate them. The author concludes that consciousness is not only a matter of information processing (though that is certainly part of it) but also a felt first-person experience. Robotic models may become more and more sophisticated in capturing some of the information processing aspects of consciousness, but whether or not this will ever lead to the first-person experience itself cannot, at the moment, be answered. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  keywords = {Artificial Intelligence,Cognitions,Cognitive Processes,Consciousness States,Language,Robotics,Self-Talk},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\8468X7CQ\\steels-03d.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\42JI3LYE\\2003-05576-010.html}
}

@article{pedersen_mel_1965,
  title = {The {{Mel Scale}}},
  author = {Pedersen, Paul},
  year = {1965},
  journal = {Journal of Music Theory},
  volume = {9},
  number = {2},
  eprint = {843164},
  eprinttype = {jstor},
  pages = {295--308},
  issn = {0022-2909},
  doi = {10.2307/843164},
  urldate = {2025-07-18}
}

@article{hockett_origin_1960,
  title = {The {{Origin}} of {{Speech}}},
  author = {Hockett, Charles F. and Hockett, Charles D.},
  year = {1960},
  journal = {Scientific American},
  volume = {203},
  number = {3},
  eprint = {24940617},
  eprinttype = {jstor},
  pages = {88--97},
  publisher = {Scientific American},
  issn = {0036-8733},
  urldate = {2025-05-27},
  file = {C:\Users\u0128513\Zotero\storage\8VUQYWP2\Hockett and Hockett - 1960 - The Origin of Speech.pdf}
}

@article{kirby_cumulative_2008,
  title = {Cumulative Cultural Evolution in the Laboratory: {{An}} Experimental Approach to the Origins of Structure in Human Language},
  shorttitle = {Cumulative Cultural Evolution in the Laboratory},
  author = {Kirby, Simon and Cornish, Hannah and Smith, Kenny},
  year = {2008},
  month = aug,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {105},
  number = {31},
  pages = {10681--10686},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.0707835105},
  urldate = {2022-10-04},
  file = {C:\Users\u0128513\Zotero\storage\SJYMTPYN\Kirby et al. - 2008 - Cumulative cultural evolution in the laboratory A.pdf}
}

@article{beckner_language_2009,
  title = {Language {{Is}} a {{Complex Adaptive System}}: {{Position Paper}}},
  shorttitle = {Language {{Is}} a {{Complex Adaptive System}}},
  author = {Beckner, Clay and Blythe, Richard and Bybee, Joan and Christiansen, Morten H. and Croft, William and Ellis, Nick C. and Holland, John and Ke, Jinyun and {Larsen-Freeman}, Diane and Schoenemann, Tom},
  year = {2009},
  journal = {Language Learning},
  volume = {59},
  number = {s1},
  pages = {1--26},
  issn = {1467-9922},
  doi = {10.1111/j.1467-9922.2009.00533.x},
  urldate = {2025-10-02},
  abstract = {Language has a fundamentally social function. Processes of human interaction along with domain-general cognitive processes shape the structure and knowledge of language. Recent research in the cognitive sciences has demonstrated that patterns of use strongly affect how language is acquired, is used, and changes. These processes are not independent of one another but are facets of the same complex adaptive system (CAS). Language as a CAS involves the following key features: The system consists of multiple agents (the speakers in the speech community) interacting with one another. The system is adaptive; that is, speakers' behavior is based on their past interactions, and current and past interactions together feed forward into future behavior. A speaker's behavior is the consequence of competing factors ranging from perceptual constraints to social motivations. The structures of language emerge from interrelated patterns of experience, social interaction, and cognitive mechanisms. The CAS approach reveals commonalities in many areas of language research, including first and second language acquisition, historical linguistics, psycholinguistics, language evolution, and computational modeling.},
  copyright = {{\copyright} 2009 Language Learning Research Club, University of Michigan},
  langid = {english},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\WRXR6SMX\\Group” et al. - 2009 - Language Is a Complex Adaptive System Position Paper.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\ZP4UWCD3\\j.1467-9922.2009.00533.html}
}

@article{bell_predictability_2009,
  title = {Predictability Effects on Durations of Content and Function Words in Conversational {{English}}},
  author = {Bell, Alan and Brenier, Jason M. and Gregory, Michelle and Girand, Cynthia and Jurafsky, Dan},
  year = {2009},
  month = jan,
  journal = {Journal of Memory and Language},
  volume = {60},
  number = {1},
  pages = {92--111},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2008.06.003},
  urldate = {2023-01-09},
  abstract = {In a regression study of conversational speech, we show that frequency, contextual predictability, and repetition have separate contributions to word duration, despite their substantial correlations. We also found that content- and function-word durations are affected differently by their frequency and predictability. Content words are shorter when more frequent, and shorter when repeated, while function words are not so affected. Function words have shorter pronunciations, after controlling for frequency and predictability. While both content and function words are strongly affected by predictability from the word following them, sensitivity to predictability from the preceding word is largely limited to very frequent function words. The results support the view that content and function words are accessed differently in production. We suggest a lexical-access-based model of our results, in which frequency or repetition leads to shorter or longer word durations by causing faster or slower lexical access, mediated by a general mechanism that coordinates the pace of higher-level planning and the execution of the articulatory plan.},
  langid = {english},
  keywords = {Content words,Function words,Models of speech production,Predictability,Word duration,Word frequency},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\AT7KRTQ8\\Bell et al. - 2009 - Predictability effects on durations of content and.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\VRDIDI67\\S0749596X08000600.html}
}

@article{aitchison_zipfs_2016,
  title = {Zipf's {{Law Arises Naturally When There Are Underlying}}, {{Unobserved Variables}}},
  author = {Aitchison, Laurence and Corradi, Nicola and Latham, Peter E.},
  year = 2016,
  month = dec,
  journal = {PLOS Computational Biology},
  volume = {12},
  number = {12},
  pages = {e1005110},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1005110},
  urldate = {2025-11-28},
  abstract = {Zipf's law, which states that the probability of an observation is inversely proportional to its rank, has been observed in many domains. While there are models that explain Zipf's law in each of them, those explanations are typically domain specific. Recently, methods from statistical physics were used to show that a fairly broad class of models does provide a general explanation of Zipf's law. This explanation rests on the observation that real world data is often generated from underlying causes, known as latent variables. Those latent variables mix together multiple models that do not obey Zipf's law, giving a model that does. Here we extend that work both theoretically and empirically. Theoretically, we provide a far simpler and more intuitive explanation of Zipf's law, which at the same time considerably extends the class of models to which this explanation can apply. Furthermore, we also give methods for verifying whether this explanation applies to a particular dataset. Empirically, these advances allowed us extend this explanation to important classes of data, including word frequencies (the first domain in which Zipf's law was discovered), data with variable sequence length, and multi-neuron spiking activity.},
  langid = {english},
  keywords = {Computational linguistics,Covariance,Entropy,Grammar,Linguistic morphology,Neurons,Probability distribution,Statistical mechanics},
  file = {C:\Users\u0128513\Zotero\storage\66CC72JB\Aitchison et al. - 2016 - Zipf’s Law Arises Naturally When There Are Underlying, Unobserved Variables.pdf}
}

@incollection{pierrehumbert_exemplar_2001,
  title = {Exemplar Dynamics: {{Word}} Frequency, Lenition and Contrast},
  booktitle = {Frequency and the {{Emergence}} of {{Linguistic Structure}}},
  author = {Pierrehumbert, Janet B.},
  editor = {Bybee, Joan and Hopper, Paul J.},
  year = 2001,
  series = {Typological Studies in Language},
  volume = {45},
  pages = {137--158},
  publisher = {John Benjamins Publishing Company},
  address = {Amsterdam},
  urldate = {2024-02-07},
  abstract = {This title addresses the question of what types of elements are frequently used in discourse, and how frequency of use affects cognitive representations.},
  isbn = {978-90-272-2947-2},
  langid = {english}
}

@article{steels_modeling_2011,
  title = {Modeling the Cultural Evolution of Language},
  author = {Steels, Luc},
  year = 2011,
  month = dec,
  journal = {Physics of Life Reviews},
  volume = {8},
  number = {4},
  pages = {339--356},
  issn = {1571-0645},
  doi = {10.1016/j.plrev.2011.10.014},
  urldate = {2020-10-13},
  abstract = {The paper surveys recent research on language evolution, focusing in particular on models of cultural evolution and how they are being developed and tested using agent-based computational simulations and robotic experiments. The key challenges for evolutionary theories of language are outlined and some example results are discussed, highlighting models explaining how linguistic conventions get shared, how conceptual frameworks get coordinated through language, and how hierarchical structure could emerge. The main conclusion of the paper is that cultural evolution is a much more powerful process that usually assumed, implying that less innate structures or biases are required and consequently that human language evolution has to rely less on genetic evolution.},
  langid = {english},
  keywords = {Biolinguistics,Cultural evolution,Evolutionary linguistics,Language evolution,Semiotic dynamics},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\PKZBITGE\\Steels - 2011 - Modeling the cultural evolution of language.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\Q8YRRT4M\\S1571064511001060.html}
}

@article{dekker_conversational_2024,
  title = {Conversational Priming in Repetitional Responses as a Mechanism in Language Change: Evidence from Agent-Based Modelling},
  shorttitle = {Conversational Priming in Repetitional Responses as a Mechanism in Language Change},
  author = {Dekker, Peter and Gipper, Sonja and de Boer, Bart},
  year = 2024,
  month = nov,
  journal = {Linguistics Vanguard},
  publisher = {De Gruyter Mouton},
  issn = {2199-174X},
  doi = {10.1515/lingvan-2023-0187},
  urldate = {2024-11-27},
  abstract = {In this article, we investigate if conversational priming in repetitional responses could be a factor in language change. In this mechanism, an interlocutor responds to an utterance by the other interactant using a repetitional response. Due to comprehension-to-production priming, the interlocutor producing the repetitional response is more likely to employ the same linguistic variant as the interlocutor producing the original utterance, resulting in a double exposure to the variant which, in turn, is assumed to reinforce the original priming effect, making the form more familiar to the repeating interlocutor. An agent-based model, with interactions shaped as conversations, shows that when conversational priming is added as a parameter, interlocutors converge faster on their linguistic choices than without conversational priming. Moreover, we find that when an innovative form is in some way favoured over another form (replicator selection), this convergence also leads to faster spread of innovations across a population. In a second simulation, we find that conversational priming is, under certain assumptions, able to overcome the conserving effect of frequency. Our work highlights the importance of including the conversation level in models of language change that link different timescales.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  keywords = {agent-based modelling,language change,priming,repetitional responses,subject marking},
  file = {C:\Users\u0128513\Zotero\storage\BVHQL2BV\Dekker et al. - 2024 - Conversational priming in repetitional responses as a mechanism in language change evidence from ag.pdf}
}

@book{goldberg_constructions_2006,
  title = {Constructions at {{Work}}: {{The Nature}} of {{Generalization}} in {{Language}}},
  shorttitle = {Constructions at {{Work}}},
  author = {Goldberg, Adele},
  year = 2006,
  publisher = {Oxford University Press},
  doi = {10.1093/acprof:oso/9780199268511.001.0001},
  urldate = {2025-07-07},
  abstract = {This book investigates the nature of generalizations in language, drawing parallels between our linguistic knowledge and more general conceptual knowledge. The book combines theoretical, corpus, and experimental methodology to provide a constructionist account of how linguistic generalizations are learned, and how cross-linguistic and language-internal generalizations can be explained. Part I argues that broad generalizations involve the surface forms in language, and that much of our knowledge of language consists of a delicate balance of specific items and generalizations over those items. Part II addresses issues surrounding how and why generalizations are learned and how they are constrained. Part III demonstrates how independently needed pragmatic and cognitive processes can account for language-internal and cross-linguistic generalizations, without appeal to stipulations that are specific to language.},
  isbn = {978-0-19-926851-1},
  file = {C:\Users\u0128513\Zotero\storage\NZSP3P5P\9780199268511.001.html}
}

@phdthesis{landsbergen_cultural_2009,
  title = {{Cultural evolutionary modeling of patterns in language change: Exercises in evolutionary linguistics}},
  shorttitle = {{Cultural evolutionary modeling of patterns in language change}},
  author = {Landsbergen, Frank},
  year = 2009,
  month = sep,
  address = {Leiden},
  urldate = {2023-01-24},
  abstract = {Frank Landsbergen - Cultural evolutionary modeling of patterns in language change},
  collaborator = {Verhagen, Arie and Lachlan, Robert F.},
  langid = {dutch},
  school = {Universiteit Leiden},
  file = {C:\Users\u0128513\Zotero\storage\NXY7BBFF\Landsbergen - 2009 - Cultural evolutionary modeling of patterns in lang.pdf}
}

@article{beuls_agent-based_2013,
  title = {Agent-{{Based Models}} of {{Strategies}} for the {{Emergence}} and {{Evolution}} of {{Grammatical Agreement}}},
  author = {Beuls, Katrien and Steels, Luc},
  year = 2013,
  journal = {PloS one},
  volume = {8},
  number = {3},
  pages = {e58960},
  publisher = {Public Library of Science PLoS, Public Library of Science},
  address = {United States},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0058960},
  abstract = {Grammatical agreement means that features associated with one linguistic unit (for example number or gender) become associated with another unit and then possibly overtly expressed, typically with morphological markers. It is one of the key mechanisms used in many languages to show that certain linguistic units within an utterance grammatically depend on each other. Agreement systems are puzzling because they can be highly complex in terms of what features they use and how they are expressed. Moreover, agreement systems have undergone considerable change in the historical evolution of languages. This article presents language game models with populations of agents in order to find out for what reasons and by what cultural processes and cognitive strategies agreement systems arise. It demonstrates that agreement systems are motivated by the need to minimize combinatorial search and semantic ambiguity, and it shows, for the first time, that once a population of agents adopts a strategy to invent, acquire and coordinate meaningful markers through social learning, linguistic self-organization leads to the spontaneous emergence and cultural transmission of an agreement system. The article also demonstrates how attested grammaticalization phenomena, such as phonetic reduction and conventionalized use of agreement markers, happens as a side effect of additional economizing principles, in particular minimization of articulatory effort and reduction of the marker inventory. More generally, the article illustrates a novel approach for studying how key features of human languages might emerge.},
  collaborator = {Sol{\'e}, Ricard V.},
  langid = {english},
  file = {C:\Users\u0128513\Zotero\storage\ADBG53RJ\Beuls and Steels - 2013 - Agent-Based Models of Strategies for the Emergence.pdf}
}

@article{pijpops_lectal_2022,
  title = {Lectal Contamination: {{Evidence}} from Corpora and from Agent-Based Simulation},
  shorttitle = {Lectal Contamination},
  author = {Pijpops, Dirk},
  year = 2022,
  month = jul,
  journal = {International Journal of Corpus Linguistics},
  volume = {27},
  number = {3},
  pages = {259--290},
  publisher = {John Benjamins},
  issn = {1384-6655, 1569-9811},
  doi = {10.1075/ijcl.20040.pij},
  urldate = {2022-10-05},
  abstract = {Abstract This paper presents evidence from both corpora and agent-based simulation for the effect of lectal contamination. By doing so, it shows how agent-based simulation can be used as a complementary technique to corpus research in the study of language variation. Lectal contamination is an effect whereby the words that are typical of a language variety more often appear in a morphosyntactic variant typical of that same variety, even among language use from a different variety. This study looks at the Dutch partitive genitive construction, which exhibits variation between a ``Netherlandic'' variant with -s ending and a ``Belgian'' variant without -s ending. It is shown that the probability of the Belgian variant without -s increases among more ``Belgian'' words, in the language use of both Belgians and people from the Netherlands. Meanwhile, an agent-based simulation reveals the crucial theoretical preconditions that lead to this effect.},
  langid = {english},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\FJWAWC44\\Pijpops - 2022 - Lectal contamination Evidence from corpora and fr.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\ZYL3KKD7\\ijcl.20040.html}
}

@article{dale_understanding_2012,
  title = {Understanding the Origins of Morphological Diversity: The Linguistic Niche Hypothesis},
  shorttitle = {Understanding the Origins of Morphological Diversity},
  author = {Dale, Rick and Lupyan, Gary},
  year = 2012,
  month = may,
  journal = {Advances in Complex Systems},
  volume = {15},
  number = {03n04},
  pages = {1150017},
  publisher = {World Scientific Publishing Co.},
  issn = {0219-5259},
  doi = {10.1142/S0219525911500172},
  urldate = {2025-12-11},
  abstract = {Human language is unparalleled in both its expressive capacity and its diversity. What accounts for the enormous diversity of human languages [13]? Recent evidence suggests that the structure of languages may be shaped by the social and demographic environment in which the languages are learned and used. In an analysis of over 2000 languages Lupyan and Dale [25] demonstrated that socio-demographic variables, such as population size, significantly predicted the complexity of inflectional morphology. Languages spoken by smaller populations tend to employ more complex inflectional systems. Languages spoken by larger populations tend to avoid complex morphological paradigms, employing lexical constructions instead. This relationship may exist because of how language learning takes place in these different social contexts [44, 45]. In a smaller population, a tightly-knit social group combined with exclusive or almost exclusive language acquisition by infants permits accumulation of complex inflectional forms. In larger populations, adult language learning and more extensive cross-group interactions produce pressures that lead to morphological simplification. In the current paper, we explore this learning-based hypothesis in two ways. First, we develop an agent-based simulation that serves as a simple existence proof: As adult interaction increases, languages lose inflections. Second, we carry out a correlational study showing that English-speaking adults who had more interaction with non-native speakers as children showed a relative preference for over-regularized (i.e. morphologically simpler) forms. The results of the simulation and experiment lend support to the linguistic niche hypothesis: Languages may vary in the ways they do in part due to different social environments in which they are learned and used. In short, languages adapt to the learning constraints and biases of their learners.},
  keywords = {agent-based simulation,Language change,morphology,social structure}
}

@article{ferreira_how_2005,
  title = {How Do Speakers Avoid Ambiguous Linguistic Expressions?},
  author = {Ferreira, Victor S. and Slevc, L. Robert and Rogers, Erin S.},
  year = 2005,
  month = jul,
  journal = {Cognition},
  volume = {96},
  number = {3},
  pages = {263--284},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2004.09.002},
  urldate = {2025-12-12},
  abstract = {Three experiments assessed how speakers avoid linguistically and nonlinguistically ambiguous expressions. Speakers described target objects (a flying mammal, bat) in contexts including foil objects that caused linguistic (a baseball bat) and nonlinguistic (a larger flying mammal) ambiguity. Speakers sometimes avoided linguistic-ambiguity, and they did so equally regardless of whether they also were about to describe foils. This suggests that comprehension processes can sometimes detect linguistic-ambiguity before producing it. However, once produced, speakers consistently avoided using the same linguistically ambiguous expression again for a different meaning. This suggests that production processes can successfully detect linguistic-ambiguity after-the-fact. Speakers almost always avoided nonlinguistic-ambiguity. Thus, production processes are especially sensitive to nonlinguistic- but not linguistic-ambiguity, with the latter avoided consistently only once it is already articulated.},
  keywords = {Ambiguity,Homophones,Language production,Monitoring,Referential communication},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\6TWHHTA5\\Ferreira et al. - 2005 - How do speakers avoid ambiguous linguistic expressions.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\VKTRUS22\\S0010027704001684.html}
}

@article{hartsuiker_error_2001,
  title = {Error {{Monitoring}} in {{Speech Production}}: {{A Computational Test}} of the {{Perceptual Loop Theory}}},
  shorttitle = {Error {{Monitoring}} in {{Speech Production}}},
  author = {Hartsuiker, Robert J. and Kolk, Herman H. J.},
  year = 2001,
  month = mar,
  journal = {Cognitive Psychology},
  volume = {42},
  number = {2},
  pages = {113--157},
  issn = {0010-0285},
  doi = {10.1006/cogp.2000.0744},
  urldate = {2025-12-12},
  abstract = {A theory of speech monitoring, proposed by Levelt (1983), assumes that the quality of one's speech is checked by the speech comprehension system. This system inspects one's own overt speech but would also inspect an inner speech plan (``the inner loop''). We have elaborated and tested this theory by way of formalizing it as a computational model. This model includes a new proposal concerning the timing relation between planning the interruption and the repair: the proposal that these two processes are performed in parallel. We attempted to simulate empirical data about the distribution of error-to-cutoff and cutoff-to-repair intervals and the effect of speech rate on these intervals (these intervals are shorter with faster speech). The main questions were (1) Is an inner monitor that utilizes the speech perception system fast enough to simulate the timing data? (2) Can the model account for the effects of speech rate on these intervals? We conclude that including an inner loop through the speech comprehension system generates predictions that fit the empirical data. The effects of speed can be accounted for, given our proposal about the time course of planning interruption and repair. A novel prediction is that the error-to-cutoff interval decreases with increasing position in the phrase.},
  keywords = {Key Words: monitoring,main interruption rule,perceptual loop theory},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\RQAQN4JI\\Hartsuiker and Kolk - 2001 - Error Monitoring in Speech Production A Computational Test of the Perceptual Loop Theory.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\8KUWGPQC\\S0010028500907448.html}
}

@inproceedings{schuurman_cgn_2003,
  title = {{{CGN}}, an Annotated Corpus of Spoken {{Dutch}}},
  booktitle = {Proceedings of 4th {{International Workshop}} on {{Linguistically Interpreted Corpora}} ({{LINC-03}}) at {{EACL}} 2003},
  author = {Schuurman, Ineke and Schouppe, Machteld and Hoekstra, Heleen and {van der Wouden}, Ton},
  year = 2003,
  urldate = {2022-05-01},
  file = {C:\Users\u0128513\Zotero\storage\A98TMRCX\Schuurman et al. - CGN, an annotated corpus of spoken Dutch.pdf}
}

@incollection{mandelbrot_information_1966,
  title = {Information {{Theory}} and {{Psycholinguistics}}: {{A Theory}} of {{Words Frequencies}}},
  booktitle = {Readings in {{Mathematical Social Science}}},
  author = {Mandelbrot, Benoit},
  editor = {Lazarsfeld, Paul F. and Henry, Neil W.},
  year = 1966,
  publisher = {Science Research Associates}
}

@article{montemurro_beyond_2001,
  title = {Beyond the {{Zipf}}--{{Mandelbrot}} Law in Quantitative Linguistics},
  author = {Montemurro, Marcelo A.},
  year = 2001,
  month = nov,
  journal = {Physica A: Statistical Mechanics and its Applications},
  volume = {300},
  number = {3},
  pages = {567--578},
  issn = {0378-4371},
  doi = {10.1016/S0378-4371(01)00355-7},
  urldate = {2025-12-15},
  abstract = {In this paper the Zipf--Mandelbrot law is revisited in the context of linguistics. Despite its widespread popularity the Zipf--Mandelbrot law can only describe the statistical behaviour of a rather restricted fraction of the total number of words contained in some given corpus. In particular, we focus our attention on the important deviations that become statistically relevant as larger corpora are considered and that ultimately could be understood as salient features of the underlying complex process of language generation. Finally, it is shown that all the different observed regimes can be accurately encompassed within a single mathematical framework recently introduced by C. Tsallis.},
  keywords = {Human language,Zipf-Mandelbrot law},
  file = {C\:\\Users\\u0128513\\Zotero\\storage\\R8855VFT\\Montemurro - 2001 - Beyond the Zipf–Mandelbrot law in quantitative linguistics.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\YMJEDBD9\\montemurro2001.pdf;C\:\\Users\\u0128513\\Zotero\\storage\\FKNMLI3S\\S0378437101003557.html}
}

@article{kong_frequency_2019,
  title = {Frequency {{Effect}} and {{Neutralization}} of {{Tones}} in {{Mandarin Chinese}}},
  author = {Kong, Huifang and Shengyi, Wu},
  year = 2019,
  month = apr,
  journal = {Journal of Quantitative Linguistics},
  volume = {26},
  number = {2},
  pages = {95--115},
  publisher = {Routledge},
  issn = {0929-6174},
  doi = {10.1080/09296174.2018.1452140},
  urldate = {2025-12-20},
  abstract = {Tonal neutralization in Mandarin has long been thought to be connected with lexical frequency. But this has never been investigated quantitatively because of the methodological challenge. In this study, a production experiment was run with speakers reading disyllabic words in neutral tones with frequency estimates derived from a Frequency Dictionary. The dependent measures were the three acoustic correlates of: duration, F0 contour and intensity. Independent measures included the lexical frequency at three levels (low, middle and high). Regression analysis showed that neutralization of tones are directly correlated with lexical frequency independent of other factors. A regularity, the more frequent, the shorter in duration; the more frequent, the lower in pitch; the more frequent, the weaker in intensity governs the neutralization of tones in reduced syllables. However, the exact shape of such an effect displays a different scenario in a different frequency range. Only high frequency words display a significant difference from low frequency words. Last but not the least, an exemplar representation is proposed to express a neutral tone's observed frequency effect naturally.},
  keywords = {exemplar approach,Lexical frequency,Mandarin,neutral tone}
}
