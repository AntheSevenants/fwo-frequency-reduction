---
title: "FWO frequency reduction article"
author:
  - name: Anthe Sevenants
    email: anthe.sevenants@kuleuven.be
    orcid: 0000-0002-5055-770X
    affiliations:
      - name: KU Leuven
  - name: Freek Van de Velde
    email: freek.vandevelde@kuleuven.be
    orcid: 0000-0003-3050-2207
    affiliations:
      - name: KU Leuven
  - name: Dirk Speelman
    email: dirk.speelman@kuleuven.be
    orcid: 0000-0003-1561-1851
    affiliations:
      - name: KU Leuven
  - name: Dirk Pijpops
    email: dirk.pijpops@uantwerpen.be
    orcid: 0000-0002-3820-8099
    affiliations:
      - name: Universiteit Antwerpen
format:
  html:
    toc: true
    css: style.css
  docx:
    toc: false
filters:
  - tikz
editor: source
title-block-banner: true
bibliography: references.bib
toc: true
toc-depth: 4
toc-location: left
tbl-cap-location: bottom
fig-cap-location: bottom
number-sections: true
reference-location: margin
csl: chicago-author-date.csl
df-print: kable
abstract: |
  TODO
execute:
  echo: false
---

## Introduction {#sec-introduction}

Many processes in language change are characterised by frequency effects. Because of the way in which certain constructions are used more often than others, complex processes such as grammaticalisation can arise [todo]. Another example of a frequency effect is the reducing effect [bybee], which dictates that as constructions are used often, their phonetic representations become more sparse. Since the frequency of a construction is directly related to its reduction, this implies that high frequency constructions experience more severe reduction, while low frequency constructions experience reduction to a lesser extent.

The reason for the reduction process is so-called "neuromotor automation", according to Bybee [todo]:

> When sequences of neuromotor routines are repeated, their execution becomes more fluent [todo bybee]

This process of neuromotor automation is assumed to be the result of two adjacent processes: temporal reduction and substantive reduction [Mowrey & Pagliuca + Pagliuca & Mowrey]. Temporal reduction entails the compression of several articulatory gestures[^gesture] into one, while substantive reduction entails the reduction in magnitude of an articulatory gesture. The combined effect of these two processes is then known under the more general term "reduction".

[^gesture]: An articulatory gesture can be defined as a movement of an articulator with an observable effect [todo].

### Empirical traces of reduction

[empirical displays of reducing effect]

### "Cause" of reduction

While we know from corpus studies that reduction patterns can indeed be found in textual data, and are therefore likely to exist, what we cannot glean from corpora is the causality that led to these patterns. As a corpus only shows the resulting *effect* of language use on a large scale, we cannot see the decisions on the level of the individual that caused there to be a reduction effect in the first place. We do not know, should reality have looked different, whether the reduction effect would still exist, as we do not know the factors that make the reduction effect occur. In other words, while we see the reducing effect in corpus data, we do not really know what *causes* it.

Empirically, it is impossible (and perhaps undesirable) to change reality in the past in order to trace any cascading effects in the long term.[^time-travel] To find the requirements of the reduction effect in spite of this, we turn to computer simulations. Computer simulations allow one to virtualise reality into a model in which virtual language users ("agents") communicate with each other on the basis of simple, local rules. The idea is that the interplay of their interactions leads to emergent linguistic behaviour, which in our case is the reducing effect. Our goal in this article is to investigate which set of requirements is needed for the agents in our computer model to exhibit reduction, displaying the same properties as those found in corpus data. Because we work with computer simulations, we can assume several outlooks on reality and the reduction effect, and try several assumptions in order to find the absolute minimal requirements needed for the reduction effect to occur.

[^time-travel]: Any researchers who have managed to receive funding for time travel are encouraged to send us an email.

While the real world is far messier and noisier than the idealised world represented in our simulations, simulation results can nevertheless "suggest that such underlying principles may operate in the real world as well" [stanford kenny p 122]. In our specific case, a simulation might show that typical reduction behaviour does not arise out of the preconditions that are presupposed in the literature, or that additional preconditions are required. Such outcomes can be theoretically interesting, since they make the various aspects of reduction theory more explicit, and since they can function as a stepping stone for further experimental or empirical research.

## Preconditions {#sec-preconditions}

We mentioned in the previous section that our goal for this study is to find the minimal requirements which produce the reducing effect as defined by Bybee [todo] (see @sec-introduction). In this section, we go over some preconditions which we assume are necessary to model reduction in a linguistically accurate away. For this, we base ourselves on empirical research [as recommended by Loreto] in the usage-based linguistics paradigm [todo referentie]. Usage-based linguistics views language as a complex-adaptive system, i.e. a system shaped through repeated use by different language users [todo referentie]. This makes it a natural fit for our simulation experiments, which operate on the same principle.

[todo: ik ben niet blij met hoe deze requirements "random" lijken, ze komen uit het niets. je hebt ze nodig maar dat weet je nog niet op dit punt. hoe oplossen?]

A first precondition for reduction is a basic principle of communication itself: shared code. Language users must refer to the same concepts using roughly the same constructions, lest they cannot communicate. The presence of a shared code does not inhibit the reorganisation of the linguistic system to be more sparse (i.e. reduction), but it is a prerequisite for a reorganisation nonetheless.

A second precondition for reduction is related to the memory that a language user should have. We know from constructions like *I don't know* eroding into forms like *dunno* that higher-order storage and representation of constructions is necessary. If constructions were stored in a compositional way (i.e. only existing as the combination of lower-order building blocks), there would be no way for a construction as a whole to reduce. This indicates that any model of reduction should feature a memory that is based on exemplar theory [todo]: a memory built up as a collection of possible realisations of different constructions. This allows for variation among those constructions, e.g. different realisations of *yes*: *yeah*, *yep*, *yup* ...  [todo misschien nog iets over voordeel vanwege frequency effects]

A third precondition for reduction is rooted in frequency. We know from corpus research that reduction affects high and low frequency constructions differently. Therefore, it is important that a model of reduction should implement linguistic frequency accurately, i.e. according to Zipf's Law [todo Zipf]. Zipf's Law dictates that many "units" in language (words, constructions, sounds ...) naturally occur according to a power law in which rank is inversely related to frequency. This means that the first item in a Zipfian distribution is twice as frequent as the second item, which in turn is twice as frequent as the third item, and so on. In practice, this leads to an extremely unbalanced distribution with few highly frequent items, and a long tail of infrequent items. This uneven distribution is also called an "A-curve" by @todo-kretzschmar. Note that, since linguistic items occur in an A-curve, so should the items in a language user's exemplar memory [todo Kretzschmar hst 3, also "probability matching" from Labov].

A final precondition for reduction is that language users should have a tendency to reduce words. This tendency arises naturally out of the so-called "Principle of Least Effort" [todo zipf], which dictates that when possible, language users will attempt to conserve as much energy as possible when speaking. This requires speakers to make an estimation of how much they can compress their utterance not to impede comprehension. This balance between energy conservation and utterance comprehension is a key dynamic behind reduction.

Note that there is no built-in requirement which dictates that frequent forms should reduce faster and to a larger extent than less frequent forms. Rather, this is the emergent behaviour that needs to occur naturally out of the interplay of the different requirements.

## Model design

### Design overview

Our simulation model design starts from the preconditions from @sec-preconditions. As such, we built a model architecture with the following properties:

- a community of $N$ agents which is implied to share the same code
- agent memories which allow the storage of different forms belonging to the same concept
- a shared vocabulary, organised through a Zipfian distribution
- a fixed probability for agents to reduce a form before uttering it

### Formalisation of speech

For our reduction simulation, we made the decision to model speech using vector representations. Such vector representations are popular in the field of machine learning, both to represent meaning [@mikolov_efficient_2013] and acoustic information [@baevski_wav2vec_2020]. Since this model pertains to oral communication, having vector representations comparable to those found in the Speech Recognition field is especially interesting given the fact that reduction can also happen on a tonal level, e.g. in Mandarin [todo de smet]. Such reduction effects cannot be encoded in a typical written form, but they can be using vectors if we assume that the vectors encode phonetic information on all levels.

For the basis of our vectors, we made the deliberate decision not to use any data from actual natural languages, since we wanted our model to be maximally language agnostic. Instead, we opted to use randomly generated speech representations, generating a matrix of $V \times M$, with $V$ being the number of constructions in the vocabulary of the agents and $M$ being the number of dimensions.[^parameters] The values of the vectors are randomly generated natural numbers between 0 and 100 [todo aanpassen aan ondergrens?]. An example of the base vector representations for the constructions in our model is given in @tbl-model_design_speech_vector_examples.

|  Construction  | Dim 1 | Dim 2 | Dim 3 | ... | Dim $M$ |
| -------------- | ----- | ----- | ----- | ----- | ----- |
| Construction 1 | 35    | 75    | 85    | ...   | 15    |
| Construction 2 | 87    | 72    | 47    | ...   | 67    |
| ... | | | | |
| Construction $V$ | 65    | 45    | 57    | ...   | 88    |

: Example base vector representations for the constructions in the simulation model. {#tbl-model_design_speech_vector_examples}

[^parameters]: We will later discuss the exact parameters chosen.

### Agent memory

Each agent has a memory of $L$ exemplars. This memory can be thought of as a matrix of size $L \times M$, with a separate mapping of size $L$ which keeps track of which exemplar belongs to which concept. An example of an agent's memory and an example population with different vector associations can be found in @tbl-model_design_agent_memory_example.

|  Exemplar  | Dim 1 | Dim 2 | Dim 3 | ... | Dim $M$ | Associated construction |
| ---------- | ----- | ----- | ----- | --- | ----- | ------ |
| Exemplar 1 | 31    | 42    | 100    | ...   | 15    | Construction 15 |
| Exemplar 2 | 27    | 37    | 27    | ...   | 97    | Construction 87 |
| ... | | | | |
| Exemplar $L$ | 44    | 39    | 69    | ...   | 80    | Construction $V$ |

: Example agent memory consisting of vector representations belonging to different constructions. {#tbl-model_design_agent_memory_example}

At the model initialisation stage, we seed each agent's exemplar memory with one vector representation for each construction, i.e. $V$ exemplars in total. We then further fill this memory following Zipf's law (see @sec-preconditions): one additional representation is added until the number of exemplars reaches $L$. Because sampling is Zipfian, popular constructions are more likely to be well represented in an agent's memory than rare constructions ["probability matching", Labov]. Note that the Zipfian distribution of exemplars in an agent's memory would be the natural outcome of communication anyway. However, by pre-filling the memory, we keep the number of forms in memory constant throughout the simulation, which should guarantee consistent model behaviour.

In this model initialisation stage, vector representations are not copied to an agent's memory one-to-one. Instead, noise is added in order to account for the natural variation in different speakers' idiomatic patterns. This noise added is drawn from a normal distribution with $\mu = 5$ and $\sigma = 1$. Substantially larger noise patterns would cause the distinctions between different constructions to become lost.

[ misschien todo prentje? ]

Because an agent's memory is limited to size $L$, whenever a new form needs to be stored, an older form needs to be removed or "forgotten". We apply the logic that the oldest exemplar that is not the last exemplar left of a construction is deleted. In this way, we avoid situations where the only exemplar left of a construction is removed, which would cause issues with mutual comprehension later in the simulation. Of course, forgetting a specific construction is normal in real life, but we avoid this occurrence in the simulation in order to keep the simulation mechanics as straightforward as possible. An example of the forgetting mechanic is given in @tbl-model_design_forgetting_example.

|  Exemplar  | Age in model steps | Associated construction | Exemplars left for construction |
| ---- | -----        | -----                   | ----- |
| Exemplar 1 | 1575 | Construction 15 | 2 |
| ~~Exemplar 2~~ | 2789 | Construction 15 | 2 |
| Exemplar 3 | 3009 | Construction 87 | 1 |
| ... | | | | |
| Exemplar $L$ | | | Construction $V$ |

: An example of how "forgetting" an exemplar works in the model. Even though Exemplar 3 is the oldest exemplar in the memory, because it is the last exemplar associated with Construction 87, Exemplar 2 is removed instead. {#tbl-model_design_forgetting_example}

### Reduction {#sec-reduction}

At speech time (see TODO), the speaker agent has the opportunity to reduce the exemplar vector representation that they retrieved from memory. Our implementation of reduction is extremely simple: a set reduction value $R$ is removed from all dimensions of the vector at once, with $R$ also being the floor value for any dimension of a vector. Without the floor value $R$, vectors would be able to reduce all the way to zero, which is an acoustic representation of silence. Of course, communication through silence is also possible, but this contextually derivative situation is beyond the scope of our model. A schematic representation of reduction is given in @fig-model_design_reduction.

::: {#fig-model_design_reduction}
```{.tikz}
\usetikzlibrary{shapes.misc, positioning, decorations.pathreplacing}

\begin{tikzpicture}[
    box/.style={draw, minimum width=1cm, minimum height=1cm, font=\Large},
    redbox/.style={box, fill=red!30},
    brace/.style={decorate, decoration={brace, amplitude=5pt}},
    arrow/.style={->, ultra thick}
]

\node[box] (A) {35};
\node[box, right=0cm of A] (B) {37};
\node[box, right=0cm of B] (C) {75};
\node[box, right=0cm of C] (D) {85};
\node[box, right=0cm of D] (E) {62};
\node[redbox, right=0cm of E] (F) {15};

\node[box, right=2cm of F] (G) {20};
\node[box, right=0cm of G] (H) {22};
\node[box, right=0cm of H] (I) {60};
\node[box, right=0cm of I] (J) {70};
\node[box, right=0cm of J] (K) {47};
\node[redbox, right=0cm of K] (L) {15};

\draw[brace] (A.north west) -- (F.north east);
\draw[brace] (F.south east) -- (A.south west);
\draw[brace] (G.north west) -- (L.north east);
\draw[brace] (L.south east) -- (G.south west);

\draw[arrow] ([xshift=0.5cm]F.east) -- ([xshift=-0.5cm]G.west);

\end{tikzpicture}
```

How reduction works in our simulation. In this case, $R = 15$. The left vector shows the original vector as retrieved from memory. The right shows the result of reduction; 15 has been subtracted from all dimensions, except for the last, since its value is already at our floor value $R$.
:::

### Language game and course of the simulation

We mentioned that we estimate that the interaction between agents, given specific preconditions, is naturally conducive to reducing behaviour. In this section, we will explain this interactional behaviour of our virtual speakers and hearers in more detail.

At each step in the simulation, each agent in the simulation enters into a "conversation" at random with another randomly selected agent. The agent initiating the conversation functions as the speaker, the other agent functions as the hearer. In this conversation, speaker and hearer play a so-called "language game" [todo], the core of our simulation. In a language game, a speaker and a hearer agent perform a joint task rooted in language, the execution of this task naturally exerting some influence on the way language is used or organised. In our simulation, the goal of the language game is for the speaker to communicate a specific construction to the hearer, which the hearer then has to understand successfully. The exact course of the language game is as follows:

**Speaker**

1. The speaker chooses a construction to utter from the $V$ constructions available. The probability of each construction is influenced by the Zipfian A-curve, discussed in @sec-preconditions, to mirror the frequency imbalance inherent to natural language.
2. The speaker chooses an exemplar vector representation to utter for that construction. This exemplar is retrieved from the agent's memory. There is no mechanism influencing the probability of a specific exemplar being chosen, though if a specific exemplar is highly frequent and therefore well represented in memory, it of course has a high chance of being selected.
3. With a probability of $p$, reduction is applied (see @sec-reduction).
4. The (potentially reduced) vector is communicated to the hearer.

**Hearer**

1. The hearer "hears" the vector communicated by the speaker.
2. The hearer interprets the vector representation of the speaker. They calculate the cosine distance (see Equation TODO) between the spoken vector and their entire exemplar memory, and select all exemplars lower or equal to threshold $t$. The constructions associated with those exemplars are tallied, and the most frequent construction is accepted as the understood construction.[^exceptions]
3. The heard exemplar is saved in the hearer's memory and is associated with the understood construction.

[^exceptions]: In the case of a tie, communication fails. In the case that no exemplars were selected, communication fails as well.

![A schematic overview of the language game played by the speaker and hearer. The diagram shows the different steps of the language game. For the speaker, this means: choosing a concept, choosing an associated exemplar, applying reduction, and speaking the resulting vector representation. For the hearer, this means: hearing the exemplar, interpreting it by tallying the exemplars in the neighbourhood of the communicated vector location, and then finally committing the exemplar to memory.](language_game.svg){#fig-model_design_language_game}

Note that we deliberately left out any feedback mechanism from the language game. We assume that our agents can only communicate through language. Our intention was to make reduction work without the hearer agent knowing whether what they understood was indeed the construction intended by the speaker. If we implemented a way to communicate "perfect" feedback from speaker to hearer, there would be no point for our agents to communicate through language. In this way, the task our agents face also becomes harder. They need to evolve the language system into a more sparse representation without any feedback of how effective that representation actually is.

## Methodology

Because we use computer simulations, we apply a different methodology from traditional, empirical research. In this section, we will explain how we will analyse the simulation behaviour, and how we will evaluate the model as a whole, particularly how test that the preconditions outlined in @sec-preconditions are indeed the minimal set required for reduction as defined by @todo-bybee to occur.

### Simulation behaviour metrics

One of the cornerstone principles of our simulation is the complex-adaptive essence of natural language. As the language system is used, it is incrementally shaped by interactions. Therefore, it is imperative that we can minutely track exactly how the language system changes in each time step of the simulation. To this end, we compute the following metrics at each step:

1. **Communicative success:**  
  Ratio expressing in how many speaking turns the hearer understood the speaker correctly.  
  $$
  \frac{\text{\# successful turns}}{\text{\# turns}}
  $$
2. **Communicative failure:**  
  Ratio expressing in how many speaking turns the hearer understood the speaker incorrectly.  
  $$
  \frac{\text{\# failed turns}}{\text{\# turns}}
  $$
3. **Reduction success:**  
  Ratio expressing in how many speaking turns with reduction communication was successful.  
  $$
  \frac{\text{\# successful reduced turns}}{\text{\# reduced turns}}
  $$
4. **Mean agent L1:**  
  Number expressing the average L1 norm of exemplars, across all agents.  
  $$
  \frac{1}{N} \sum_{i=1}^{N}{\left[ \frac{1}{L_i} \sum_{j=1}^{L_i}{ \left[ \frac{\sum_{k=1}^{M}{ \text{agent}_i.\text{memory}_{jk}}}{M} \right] } \right]}
  $$
5. **Mean construction L1:**  
  Number expressing for each construction $t$ the average L1 norm of its exemplars, across all agents.
  $$  
  \frac{1}{N} \sum_{i=1}^{N}{ \left[ \frac{1}{L_{t_i}} \sum_{j=1}^{L_{t_i}}{ \left[ \frac{\sum_{k=1}^{M}{ \text{agent}_i.\text{memory}_{jk}}}{M} \right] } \right] }
  $$ with $L_t$ = # exemplars associated with construction $t$
6. **Confusion matrix:**  
  Confusion matrix tallying intended and understood constructions across all agents. Matrix of size $V \times V$.
7. **Outcomes:**  
  Tally of outcomes of a speaking turn, with *success*, *no exemplars in neighbourhood*, *wrong construction was most frequent*, *tie in most frequent* as possible outcomes.
8. **Mean exemplar count:**  
  Number expressing for each construction $t$ the average number of exemplars, across all agents.
  $$
  \frac{1}{N} \sum_{i=1}^{N}{ L_{t_i} }
  $$ with $L_t$ = # exemplars associated with construction $t$
9. **Success per construction:**  
  Ratio expressing for each construction $t$ in how many speaking turns the hearer understood the speaker correctly.
  $$
  \frac{\text{\# successful turns}}{\text{\# turns for construction } t}
  $$
10. **Communicative success (macro average):**  
  Ratio expressing in how many speaking turns the hearer understood the speaker correctly. Macro averaged to account for Zipfian skew.
  $$
  \frac{1}{V} \sum_{t=1}^{V}{\frac{\text{\# successful turns}}{\text{\# turns for construction } t}}
  $$
11. **Good origin ratio:**  
  Ratio expressing for each construction $t$ how many exemplars come from successful speaking turns.  
  $$
  \frac{1}{N} \sum_{i=1}^{N}{ \left[ \frac{1}{L_{t_i}} \sum_{j=1}^{L_{t_i}}{ \operatorname{good origin}(L_{t_i}) } \right] }
  $$ with $L_t$ = # exemplars associated with construction $t$ and $\operatorname{good origin}(exemplar) = \begin{cases}
0 & \text{if from failed speaking turn} \\
1 & \text{if from successful speaking turn}
\end{cases}$
12. **Mean exemplar age:**  
  Number expressing for each construction $t$ how old its exemplars are on average (in model steps).  
  $$
  \frac{1}{N} \sum_{i=1}^{N}{ \left[ \frac{1}{L_{t_i}} \sum_{j=1}^{L_{t_i}}{ \operatorname{age}(L_{t_i}) } \right] }
  $$ with $L_t$ = # exemplars associated with construction $t$ and $\operatorname{age}(exemplar)$ returning the age in steps for an exemplar.

### Expected behaviour

We will consider a set of preconditions to produce the reducing effect if the following is true:

1. The language system has reorganised itself to express the same constructions using more efficient representations.
1. Frequent forms have reduced to a greater extent than non-frequent forms.
1. Communication between agents remains successful. If the language system has reorganised itself in a way that makes effective communication impossible, the simulation has failed to simulate realistic conditions. Nonetheless, some tradeoff between communicative effort and communicative success can be seen as normal.

If the behaviour of a simulation corresponds with any of these three statements not being true, then we will say that that simulation does not produce behaviour equivalent to the behaviour found in corpus studies. The preconditions of that simulation are then said not to be conducive to the reducing effect.

### Evaluation

If any set of preconditions produces behaviour which fully falls within the expected behaviour detailed in the previous section, then we can say that that set is conducive to the reducing effect. The next question is whether this set is the *minimal* set required to produce the reducing effect.

In order to check whether a set of preconditions is also the minimal set, we will apply the principle of Occam's Razor [@todo-occam-razor]. This principle dictates that the simplest explanation for a phenomenon is presumptively the most likely one. Therefore, we will disable each precondition iteratively and check whether the simpler conditions can also produce the expected reduction behaviour. If a simpler set produces equivalent behaviour, we have found a more minimal set. If no simpler set produces equivalent behaviour, our initial set was already the minimal one.

### Parameters

In this section, we will run through the different parameters the model has and what values we chose for them. Parameters control specific aspects of our model, like how many agents inhabit our virtual world or how likely reduction is. Paradoxically, choosing the right parameter values is relatively unimportant, until it is not. The consensus in simulation research is that the outcome of a simulation should not hinge on its parameter values [stanford kenny, beuls & pijpops (zie thesis)]. For example, it usually should not matter whether 25 or 250 agents partake in a simulation[^agent-count-exception]; the emergent effect will remain the same, though it could be slower or faster. At the same time, it goes without saying that having just two or three agents in a simulation hardly makes the model world representative of an actual language "community". In the same way, while it would be hard to justify having a language of only two constructions, the difference between 100 and 1000 constructions in a modelling context is much smaller. Therefore, most of our parameter choices are practical in nature.

One of the driving forces behind our parameter choices is computational tractability. Because we work with vector representations, and interpretation hinges on vector computations on an agent's entire exemplar memory, large agent counts, high dimension counts, large vocabulary sizes and large memory sizes all cause the time it takes to run a single simulation to balloon, even on powerful server hardware. Therefore, we made the decision to keep the parameters of the simulation modest. Review @tbl-parameters for an overview of our choices.

[^agent-count-exception]: Of course, if a simulation is designed to be sensitive to agent count (i.e. because it is part of the research question), then the number of agents *does* matter.

| Parameter | Explanation | Value |
| --- | --- | --- |
| $N$ | Number of agents | 25 |
| $V$ | Number of constructions | 100 |
| $M$ | Number of vector dimensions | 100 |
| $L$ | Number of exemplars in memory | 1000 |
| $R$ | Value subtracted from exemplar vector at reduction time. Also functions as threshold floor value. A vector dimension cannot reduce below this point. | 15 |
| $t$ | Neighbourhood size. Only exemplars within this range count towards the interpretation of a vector. | 150 |
| $p$ | Reduction probability at speech time | 0.5 |
: An overview of all parameters in the simulation and their values. {#tbl-parameters}

## Results

## Discussion

possible extensions

- turning frequency into probability -> like Gregory et al. -> extension possible for contextual clues